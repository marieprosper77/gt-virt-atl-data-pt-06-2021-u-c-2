{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Yelp User's Average Rating of Italian Restaurants\n",
    "This model uses a two-step process to predict a Yelp user's average rating of Italian restaurants.\n",
    "\n",
    "The first step is to cluster Yelp restaurants based on their categories. Since we are predicting Italian restaurant ratings, Italian restaurants are removed from the clustering step. This clustering is performed with DBSCAN using an L1 metric and an epsilon of 1 (i.e. two restaurants that differ by one category are considered in the same \"neighborhood\").\n",
    "\n",
    "Then, a training set is created of users that have reviewed at least 5 Italian restaurants. A portion of this training set is held out to test the accuracy of the model. Each user's average rating by cluster is calculated. These ratings are then used as inputs to train a neural network model with the user's average rating of Italian restaurants as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in restaurant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = []\n",
    "with open('I:/yelp_dataset/restaurant_data/restaurant.json', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        restaurant = json.loads(line)\n",
    "        restaurant['categories'] = [x.strip() for x in restaurant['categories'].split(',')]\n",
    "        restaurants.append(restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_restaurants = [x for x in restaurants if 'Italian' in x['categories']]\n",
    "other_restaurants = [x for x in restaurants if 'Italian' not in x['categories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting restaurant categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "for restaurant in restaurants:\n",
    "    for category in restaurant['categories']:\n",
    "        categories.add(category)\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving restaurant categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('I:/yelp_dataset/restaurant_data/categories.json', mode='w') as f:\n",
    "    json.dump(list(categories), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_to_row(restaurant, categories):\n",
    "    row = {i: 0 for i in categories}\n",
    "    row['business_id'] = restaurant['business_id']\n",
    "    for category in restaurant['categories']:\n",
    "        row[category] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_restaurant_rows = [restaurant_to_row(x, categories) for x in other_restaurants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(other_restaurant_rows)\n",
    "X = df.drop('business_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# CAUTION! This step may take several hours\n",
    "model = DBSCAN(eps=1, metric='l1')\n",
    "model.fit(df.drop('business_id', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.labels_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = df.drop('Restaurants', axis=1)\n",
    "labeled_df['label'] = model.labels_ + 1\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df[['business_id', 'label']].to_json('I:/yelp_dataset/restaurant_data/business_clusters.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = labeled_df.groupby('label').mean()\n",
    "counts = labeled_df.groupby('label')['label'].count()\n",
    "\n",
    "for cluster in range(labeled_df['label'].max()):\n",
    "    print(f'\\nCluster {cluster}, count: {counts[cluster]}')\n",
    "    temp_df = vectors.transpose()[cluster].sort_values(ascending=False)\n",
    "    identifying_categories = temp_df[temp_df > 0.9]\n",
    "    [print(x) for x in identifying_categories.index] if len(identifying_categories > 0) else print('()')\n",
    "    print('\\n')\n",
    "    print(vectors.transpose()[cluster].sort_values(ascending=False).head())\n",
    "    print('\\n' + '-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open('I:/yelp_dataset/restaurant_data/review.json', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        reviews = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(reviews[:-1]).merge(labeled_df[['business_id','label']], on='business_id', how='left')\n",
    "df2['label'] = df2['label'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_restaurant_reviewers = df2[df2['label'] == -1].groupby('user_id').count()['label']\n",
    "top_italian_restaurant_reviewers = italian_restaurant_reviewers[italian_restaurant_reviewers >= 5]\n",
    "top_italian_restaurant_reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "italian_restaurant_ids = set([x['business_id'] for x in italian_restaurants])\n",
    "italian_restaurant_reviewer_ids = [x['user_id'] for x in reviews[:-1] if x['business_id'] in italian_restaurant_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2['user_id'].isin(top_italian_restaurant_reviewers.index)].groupby(['user_id', 'label']).mean().reset_index().set_index('user_id').pivot(columns='label', values='stars')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.drop(-1, axis=1).fillna(3)\n",
    "y = df3[-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "nn_model = tf.keras.Sequential()\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, input_dim=len(X.columns)))\n",
    "nn_model.compile(loss=\"MSE\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
    "fit_model = nn_model.fit(X_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save(\"yelp_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fit_model.history, index=range(1,len(fit_model.history[\"loss\"])+1)).plot(y=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, nn_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, nn_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nn_model.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion:*\n",
    "\n",
    "While the R-square of 0.35 shows there is room for improvement in the model, on average, the model is within .4 stars of the actual result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonAdv",
   "language": "python",
   "name": "pythonadv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
